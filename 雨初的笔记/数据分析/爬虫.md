+ `Upgrade-Insecure-Requests: 1` 用来提升为 `https` 。

+ `referer` 字段表示这个请求是从哪里过来的。有些网站可能会检查这个。这个字段也可以用来进行防盗链。

+ 在写爬虫的时候优先检查

  ```html
  User-Agent
  Referer
  Cookie
  ```

  但其他的字段也要留意。网站进行反爬也可能会使用到一些特殊的字段。

+ 响应头 `set-cookie` 用来设置 `cookie` 。

+ 不要相信得到的状态码，一切从是否能够从抓包得到的相应中获取到数据为准。

+ `network` 中抓包得到的源码才是判断依据， `elements` 中的源码是渲染后的，不能作为判断依据。

+ ![image-20211111113848555](https://raw.githubusercontent.com/smallzhong/new_new_picgo_picbed/main/image-20211111113848555.png)

+ ![image-20211111114638787](https://raw.githubusercontent.com/smallzhong/new_new_picgo_picbed/main/image-20211111114638787.png)

+ ![image-20211111115701264](https://raw.githubusercontent.com/smallzhong/new_new_picgo_picbed/main/image-20211111115701264.png)

+ ![image-20211111120854473](https://raw.githubusercontent.com/smallzhong/new_new_picgo_picbed/main/image-20211111120854473.png)

  分割 `cookie` 的方法

+ 直接从 `request` 中获取 `cookie` 字典的方法

  ![image-20211111121347609](https://raw.githubusercontent.com/smallzhong/new_new_picgo_picbed/main/image-20211111121347609.png)

+ 可以设置 `timeout` 参数，比如 `r = request.get(url, timeout=3)` ，这样就会设置超时时间为3秒。如果3秒之后还是没有得到相应，那么我们就直接停止。

+ 代理的使用

  ![image-20211111124245246](https://raw.githubusercontent.com/smallzhong/new_new_picgo_picbed/main/image-20211111124245246.png)

+ 在有 `verify` 的时候可以 `r = requests.get(url, verify=False)` 。这样会报一个警告说这个连接是一个不安全的连接，但是可以正常连接上。

+ ![image-20211111130729609](https://raw.githubusercontent.com/smallzhong/new_new_picgo_picbed/main/image-20211111130729609.png)

+ ```python
  from bs4 import BeautifulSoup
  import re
  import sys
  import requests
  
  url = "http://www.baidu.com/"
  r = requests.get(url)
  r.encoding = 'utf-8'
  
  print(r.text)
  # 响应url
  print(r.url)
  # 状态码
  print(r.status_code)
  # 请求头
  print(r.request.headers)
  # 响应头
  print(r.headers)
  # 响应cookie(set-cookie)
  print(r.cookies)
  ```

+ 